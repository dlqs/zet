---
title: Measuring Parallel Algorithms
date: 2020-09-05
tags:
 - algo
---

Sequential RAM Model
 - 1 processor, 1 memory module
 - constant time r/w
 - this is the computer we have in mind when writing loops in C or Java
 
Parallel RAM Model (PRAM)
 - multiple processors, 1/multiple memory modules
 - different variants of PRAM (because of r/w conflicts)
  - exclusive W, concurrent W, ex R, con R
  - most popular is concurrent read and exclusive write

Resolving concurrent writes: when multiple processors write to the same memory cell
 - machine dies
 - pick one write arbitrarily
 - pre-define a priority (Processor 1 > 2 > 3 etc.)
 - combination of values: max, logical OR etc. (why would this ever be a good idea?)
 - this is all based on clock ticks, which are the same for all processors
   - implies that concurrent writes can happen at the *exact* same time

Runtime
 - normally, time taken is directly proportional to number of operations (of an algo)
 - in PRAM, have to wait for slowest processor to finish, aka depth
 - T1 = wall clock time for 1 proc
 - TP = wall clock time for P procs
 
Work: time required to complete all computations times number of processors

Lower bound on work?
 - T1/P: all the work is equally divided among all processors
 - but usually there are some *sequential* parts
 
To see: draw algo as DAG
 - operations in different layers of DAG cannot be done in parallel
 - to execute sequentially: T1: num nodes in dag
 - to execute with an infinite number of procs: Tinf: depth
 - to execute with some number of procs: TP: somewhere in between
 
Depth: aka critical path, span
 - longest dependency chain
 - called Tinf
 
Brent's Law: TP is bounded by
 - T1/P < TP < T1/P + Tinf
 
 Example: summing numbers in an array
  - assign each processors a pair of elements
  - at the next level of the DAG, similarly assign each proc sums from the previous nodes
  - if array length is not even, pad with a single zero
  - Tinf? log2N
  - Brents: TP <= n/p + log2N
  - works for any associative binary operator
