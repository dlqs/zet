---
title: Functional Programming in Scala Chapter 7
date: 2021-01-10
tags:
 - scala
 - fp-scala
---

Goal: develop parMap (parallel Map) that lets us apply f to every element simultaneously.
Existing libraries like scala.concurrent already do this, but we're designing our own here.
Fully functional library.

E.g. Summing integers functionally can be done with foldleft, but can be parallelized with a divide and conquer strategy

For our parallel library 
the data type that we choose to represent parallel computations needs to be able to contain a *result*.
 - Par[A]: one "unit" of parallelism that contains its own result
 - unit[A](a: => A): Par[A]: wraps an unevaluated A in a unit of parallelism and returns Par[A]
 - get[A](a: Par[A]):A : extracts result from a Par[A]
 
Problems with java.lang.Thread and Runnable
  - start, join mutate
  - bad for compositionality
  - threads are OS threads, not logical threads like above
  - we should separate problem of logically splitting work
  and mapping logical threads to OS threads
  
java.util.concurrent.Future helps but
 - calling .get blocks
 - API provides no way to compose futures
 - we want something higher level than these

For unit(), we need to choose one of:
 - eval immd (start the computation immediately), or
 - eval later when get() is called (and hence block)
 - in both cases: unit() returns immed. (this must be the case)
 - pro for first: if we do the second, writing something like `.get + .get` is effectively sequential
 - con for first: breaks referential transparency
   - cannot replace sumLeft with Par.get(Par.unit(sum(l)). The former doesn't block, the latter does -> side effect! 

Perhaps our computation can return a Par[A] instead of just A? Part of divide and conq algo to sum array 
requires combining two Par results, which we can do with:  
`def map2[A, B, C](p1: Par[A], p2: Par[B])(f: (A, B) => C): Par[C]`

For map2(), we need to choose:
 - strict / lazy (thunk) its arguments?
 - strict: will construct entire left half of Par, all the way down
 - and if eval immd: will even start *computation* of entire left half of Pars
 - and if eval later: constructs descriptions of promises. Nothing happens till get()
 - the problem is that the descriptions (which is really a tree) takes space too!
 - lazy and eval immd
 
Do we always want both sides to be parallel? What if the work is too small? 
We can create a new construct to explicitly fork  
 - `def fork[A](a: => Par[A]): Par[A]`
 - with this, we can make map2() strict: programmer chooses when to fork

Two concerns:
 - some way to indicate results of two parallel tasks should be combined
 - whether a task should fork or not

  
Fork lets us implement lazyUnit with strict args
 - derived combinator. Unit is a primitive combinator
 
Fork should eval immd or eval later (at .get, perhaps?)
 - if immd, when fork() is created, it must know something about how to create threads (e.g. globally accessible thread pool)
 - if eval later, for is the description of promises that will be executed in another thread
 - Nothing happens till get(), which by now is really run()
 
 
  
  
  
